{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from models.CSRNet.CSRNet import CSRNet\n",
    "\n",
    "import importlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model_path = 'D:\\\\OneDrive\\\\OneDrive - UvA\\\\ThesisData\\\\trained_models\\\\CSRNet TL SHTA\\\\save_state_ep_121_new_best_MAE_74.482.pth'  # The path to trained model file (something like XYZ.pth)\n",
    "trained_model_path = 'D:\\\\OneDrive\\\\OneDrive - UvA\\\\ThesisData\\\\trained_models\\\\CSRNet TL SHTA new\\\\save_state_ep_140_new_best_MAE_84.146.pth'  # The path to trained model file (something like XYZ.pth)\n",
    "# trained_model_path = 'D:\\\\Downloads\\\\PartAmodel_best.pth.tar'  # The path to trained model file (something like XYZ.pth)\n",
    "\n",
    "\n",
    "label_factor = 100  # The label factor used to train this specific model.\n",
    "dataset = 'SHTB_CSRNet'  # Must be the exact name of the dataset\n",
    "save_results = False  # When true, save the images, GTs and predictions. A folder for this is created automatically.\n",
    "set_to_eval = 'test'  # val', 'test'. Which split to test the model on. 'train' does not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSRNet()\n",
    "\n",
    "resume_state = torch.load(trained_model_path)\n",
    "\n",
    "# new_dict = {}\n",
    "# for k, v in resume_state.items():\n",
    "#     k = k[4:]\n",
    "#     new_dict[k] = v\n",
    "# model.load_state_dict(new_dict)\n",
    "\n",
    "model.load_state_dict(resume_state['net'])\n",
    "# model.load_state_dict(resume_state['state_dict'])\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = importlib.import_module(f'datasets.standard.{dataset}.loading_data').loading_data\n",
    "cfg_data = importlib.import_module(f'datasets.standard.{dataset}.settings').cfg_data\n",
    "\n",
    "train_loader, val_loader, test_loader, restore_transform = dataloader()\n",
    "if set_to_eval == 'val' or set_to_eval == 'eval':\n",
    "    my_dataloader = val_loader\n",
    "elif set_to_eval == 'test':\n",
    "    my_dataloader = test_loader\n",
    "else:\n",
    "    print(f'Error: invalid set --> {set_to_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = None\n",
    "if save_results:\n",
    "    save_folder = 'CSRNet' + '_' + dataset + '_' + set_to_eval + '_' + time.strftime(\"%m-%d_%H-%M\", time.localtime())\n",
    "    save_path = os.path.join('notebooks', save_folder)  # Manually change here is you want to save somewhere else\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_results(save_path, img, img_idx, gt, prediction, pred_cnt, gt_cnt):\n",
    "    img_save_path = os.path.join(save_path, f'IMG_{img_idx}_AE_{abs(pred_cnt - gt_cnt):.3f}.jpg')\n",
    "    \n",
    "    plt.figure()\n",
    "    f, axarr = plt.subplots(1, 3, figsize=(13, 13))\n",
    "    axarr[0].imshow(img)\n",
    "    axarr[1].imshow(gt, cmap=cm.jet)\n",
    "    axarr[1].title.set_text(f'GT count: {gt_cnt:.3f}')\n",
    "    axarr[2].imshow(prediction, cmap=cm.jet)\n",
    "    axarr[2].title.set_text(f'predicted count: {pred_cnt:.3f}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(img_save_path)\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, my_dataloader, show_predictions, restore_transform, label_factor, cfg_data):\n",
    "    with torch.no_grad():\n",
    "        AEs = []  # Absolute Errors\n",
    "        SEs = []  # Squared Errors\n",
    "        GTs = []\n",
    "        preds = []\n",
    "\n",
    "        for idx, (img, gt) in enumerate(my_dataloader):\n",
    "            img = img.cuda()\n",
    "           \n",
    "            den = model(img)  # Precicted density crops\n",
    "            den = den.cpu()\n",
    "\n",
    "            gt = gt.squeeze()  # Remove channel dim\n",
    "            den = den.squeeze()  # Remove channel dim\n",
    "            \n",
    "            img = restore_transform(img.squeeze())  # Original image\n",
    "            pred_cnt = den.sum() / label_factor\n",
    "            gt_cnt = gt.sum() / cfg_data.LABEL_FACTOR\n",
    "            \n",
    "            AEs.append(torch.abs(pred_cnt - gt_cnt).item())\n",
    "            SEs.append(torch.square(pred_cnt - gt_cnt).item())\n",
    "            GTs.append(gt_cnt.item())\n",
    "            preds.append(pred_cnt.item())\n",
    "            relative_error = AEs[-1] / gt_cnt * 100\n",
    "            print(f'IMG {idx:<3} '\n",
    "                  f'Prediction: {pred_cnt:<9.3f} '\n",
    "                  f'GT: {gt_cnt:<9.3f} '\n",
    "                  f'Absolute Error: {AEs[-1]:<9.3f} '\n",
    "                  f'Relative Error: {relative_error:.1f}%')\n",
    "            \n",
    "            if save_path:\n",
    "                plot_and_save_results(save_path, img, idx, gt, den, pred_cnt, gt_cnt)\n",
    "            \n",
    "        MAE = np.mean(AEs)\n",
    "        MSE = np.sqrt(np.mean(SEs))\n",
    "\n",
    "    return MAE, MSE, GTs, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE, MSE, GTs, preds = eval_model(model, my_dataloader, save_path, restore_transform, label_factor, cfg_data)\n",
    "print(f'MAE/MSE: {MAE:.3f}/{MSE:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nrs = np.arange(len(GTs))\n",
    "sorted_idxs = np.argsort(GTs)\n",
    "GTs = np.array(GTs)\n",
    "preds = np.array(preds)\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(img_nrs, GTs[sorted_idxs], label='Ground truths')\n",
    "plt.plot(img_nrs, preds[sorted_idxs], label='Predictions')\n",
    "plt.ylabel('Crowd count')\n",
    "plt.xlabel('Sorted image')\n",
    "plt.legend(loc=2, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'CSRNet_{dataset}_pred_vs_gt.jpg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_error_idxs = np.flip(np.argsort(np.abs(GTs - preds)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in sorted_error_idxs[:10]:\n",
    "        img, gt = my_dataloader.dataset.__getitem__(idx)\n",
    "        img = img.unsqueeze(0)\n",
    "        gt = gt.unsqueeze(0)\n",
    "        img = img.cuda()\n",
    "\n",
    "        den = model(img)  # Precicted density crops\n",
    "        den = den.cpu()\n",
    "\n",
    "        gt = gt.squeeze()  # Remove channel dim\n",
    "        den = den.squeeze()  # Remove channel dim\n",
    "\n",
    "        img = restore_transform(img.squeeze())  # Original image\n",
    "        pred_cnt = den.sum() / label_factor\n",
    "        gt_cnt = gt.sum() / cfg_data.LABEL_FACTOR\n",
    "\n",
    "\n",
    "        print(f'IMG {idx}, pred: {pred_cnt:.3f}, gt: {gt_cnt:.3f}. Error: {pred_cnt - gt_cnt:.3f}')\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(np.asarray(img))\n",
    "        plt.title(f'GT count: {gt_cnt:.3f}')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'CSRNet_IMG_{idx + 1}_{dataset}.jpg')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        plt.figure()\n",
    "        plt.imshow(den.numpy(), cmap=cm.jet)\n",
    "        plt.title(f'Predicted count: {pred_cnt:.3f}')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'CSRNet_IMG_{idx + 1}_{dataset}_prediction.jpg')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(GTs - preds)[sorted_error_idxs[-300:]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThesisMain",
   "language": "python",
   "name": "thesismain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
