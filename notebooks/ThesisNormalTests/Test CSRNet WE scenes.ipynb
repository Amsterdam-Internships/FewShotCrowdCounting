{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from models.CSRNet.CSRNet import CSRNet\n",
    "\n",
    "import importlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_path = 'D:\\\\Bureaublad\\\\save_state_ep_560_new_best_MAE_7.454.pth'  # The path to trained model file\n",
    "label_factor = 100  # The label factor used to train this specific model.\n",
    "dataset = 'WE_CSRNet_Meta'  # Must be the exact name of the dataset\n",
    "save_results = False  # When true, save the images, GTs and predictions. A folder for this is created automatically.\n",
    "set_to_eval = 'test'  # val', 'test'. Which split to test the model on. 'train' does not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = importlib.import_module(f'datasets.meta.{dataset}.loading_data').loading_data\n",
    "cfg_data = importlib.import_module(f'datasets.meta.{dataset}.settings').cfg_data\n",
    "\n",
    "train_loaders, val_loaders, test_loaders, restore_transform = dataloader()\n",
    "if set_to_eval == 'val':\n",
    "    my_dataloaders = val_loaders\n",
    "elif set_to_eval == 'test':\n",
    "    my_dataloaders = test_loaders\n",
    "else:\n",
    "    print(f'Error: invalid set --> {set_to_eval}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "if save_results:\n",
    "    save_folder = 'CSRNet_meta' + '_' + dataset + '_' + set_to_eval + '_' + time.strftime(\"%m-%d_%H-%M\", time.localtime())\n",
    "    save_dir = os.path.join('notebooks', save_folder)  # Manually change here is you want to save somewhere else\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CSRNet()\n",
    "\n",
    "resume_state = torch.load(trained_model_path)\n",
    "\n",
    "# new_dict = {}\n",
    "# for k, v in resume_state.items():\n",
    "#     k = k[4:]\n",
    "#     new_dict[k] = v\n",
    "# model.load_state_dict(new_dict)\n",
    "\n",
    "model.load_state_dict(resume_state['net'])\n",
    "\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scene_graph(preds, gts, save_name):\n",
    "    MAE = np.mean(np.abs(np.array(preds) - np.array(gts)))\n",
    "    \n",
    "#     save_path = os.path.join(save_dir, save_name)\n",
    "    xs = np.arange(len(gts))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(f'MAE: {MAE:.3f}')\n",
    "    plt.plot(xs, gts, color='green', label='GT')\n",
    "    plt.plot(xs, preds, color='blue', label='Predictions')\n",
    "    plt.legend()\n",
    "#     plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_on_scene(model, scene_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        AEs = []  # Absolute Errors\n",
    "        SEs = []  # Squared Errors\n",
    "        gts = []\n",
    "        preds = []\n",
    "\n",
    "        for idx, (img, gt) in enumerate(scene_dataloader):\n",
    "            img = img.cuda()\n",
    "           \n",
    "            den = model(img)  # Precicted density crops\n",
    "            den = den.cpu()\n",
    "\n",
    "            gt = gt.squeeze()  # Remove channel dim\n",
    "            den = den.squeeze()  # Remove channel dim\n",
    "            \n",
    "            pred_cnt = den.sum() / label_factor\n",
    "            gt_cnt = gt.sum() / cfg_data.LABEL_FACTOR\n",
    "            \n",
    "            AEs.append(torch.abs(pred_cnt - gt_cnt).item())\n",
    "            SEs.append(torch.square(pred_cnt - gt_cnt).item())\n",
    "            gts.append(gt_cnt.item())\n",
    "            preds.append(pred_cnt.item())\n",
    "            \n",
    "        MAE = np.mean(AEs)\n",
    "        MSE = np.sqrt(np.mean(SEs))\n",
    "\n",
    "    return preds, gts, MAE, MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAEs = []\n",
    "MSEs = []\n",
    "for idx, scene_dataloader in enumerate(my_dataloaders):\n",
    "    print(f'Scene {idx + 1}')\n",
    "\n",
    "    preds, gts, MAE, MSE = eval_on_scene(model, scene_dataloader)\n",
    "    print(f'    MAE/MSE: {MAE:.3f}/{MSE:.3f}')\n",
    "    MAEs.append(MAE)\n",
    "    MSEs.append(MSE)\n",
    "\n",
    "    save_scene_graph(preds, gts, f'scene_{idx + 1}.jpg')\n",
    "    \n",
    "overal_MAE = np.mean(MAEs)\n",
    "overal_MSE = np.mean(MSEs)\n",
    "print(f'avg MAE/MSE: {overal_MAE:.3f}/{overal_MSE:.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ThesisMain",
   "language": "python",
   "name": "thesismain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
