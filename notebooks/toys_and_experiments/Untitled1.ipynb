{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:\\OneDrive\\OneDrive - UvA\\ThesisData\\Datasets\\WE_C3_PP_FSL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WEInterface():\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "        self.train_path = os.path.join(base_path, 'train')\n",
    "        self.test_path = os.path.join(base_path, 'test')\n",
    "        \n",
    "        self.train_scenes = None\n",
    "        self.test_scenes = None\n",
    "        self.frame_paths = {}\n",
    "        self.init_scenes()\n",
    "        \n",
    "    def init_scenes(self):\n",
    "        train_frames_path = os.path.join(self.train_path, 'frames')\n",
    "        self.train_scenes = os.listdir(train_frames_path)\n",
    "        for train_scene in self.train_scenes:\n",
    "            self.frame_paths[train_scene] = train_frames_path\n",
    "        \n",
    "        test_frames_path = os.path.join(self.test_path, 'frames')\n",
    "        self.test_scenes = os.listdir(test_frames_path)\n",
    "        for test_scene in self.test_scenes:\n",
    "            self.frame_paths[test_scene] = test_frames_path\n",
    "        \n",
    "        \n",
    "    def get_scenes(self):\n",
    "        return self.get_train_scenes() + self.get_test_scenes()\n",
    "    \n",
    "    def get_train_scenes(self):\n",
    "        return self.train_scenes\n",
    "    \n",
    "    def get_test_scenes(self):\n",
    "        return self.test_scenes\n",
    "         \n",
    "    def get_images(self, full_path=True):\n",
    "        pass\n",
    "    \n",
    "    def get_train_images(self, full_path=True):\n",
    "        imgs = []\n",
    "        for scene in self.train_scenes:\n",
    "            imgs += self.get_scene_images(scene, True)\n",
    "        return imgs\n",
    "    \n",
    "    def get_test_images(self, full_path=True):\n",
    "        imgs = []\n",
    "        for scene in self.test_scenes:\n",
    "            imgs += self.get_scene_images(scene, True)\n",
    "        return imgs\n",
    "        \n",
    "    def get_scene_images(self, scene, full_path=False):\n",
    "        frame_path = self.frame_paths[scene]\n",
    "        imgs_path = os.path.join(frame_path, scene)\n",
    "        imgs = os.listdir(imgs_path)\n",
    "        if full_path:\n",
    "            imgs = [os.path.join(imgs_path, img) for img in imgs]\n",
    "        return imgs\n",
    "    \n",
    "    def load_image_and_gt(self, image_path):\n",
    "        gt_path = image_path.replace('frames', 'csvs').replace('.jpg', '.csv')\n",
    "        \n",
    "        img = Image.open(image_path)\n",
    "        if img.mode == 'L':\n",
    "            print(\"Is this used?\")\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        gt = pd.read_csv(gt_path, sep=',', header=None).values\n",
    "        gt = gt.astype(np.float32, copy=False)\n",
    "        gt = Image.fromarray(gt)\n",
    "        \n",
    "        return img, gt\n",
    "    \n",
    "interface = WEInterface(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive\\OneDrive - UvA\\ThesisData\\Datasets\\WE_C3_PP_FSL\\train\\frames\\100156_A02\\100156_A02IndiaWE-03-S20100626080000000E20100626233000000_new.split.105_1.jpg\n"
     ]
    }
   ],
   "source": [
    "for img in interface.get_train_images():\n",
    "    print(img)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=720x576 at 0x226F5E6FF08>,\n",
       " <PIL.Image.Image image mode=F size=720x576 at 0x226F5E81E48>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interface.load_image_and_gt(interface.get_train_images()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
